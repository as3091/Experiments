{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c45aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd57690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting observation: [-0.03998471 -0.00902703  0.03400657 -0.01990803]\n"
     ]
    }
   ],
   "source": [
    "# Create our training environment - a cart with a pole that needs balancing\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "# Reset environment to start a new episode\n",
    "observation, info = env.reset()\n",
    "# observation: what the agent can \"see\" - cart position, velocity, pole angle, etc.\n",
    "# info: extra debugging information (usually not needed for basic learning)\n",
    "\n",
    "print(f\"Starting observation: {observation}\")\n",
    "# Example output: [ 0.01234567 -0.00987654  0.02345678  0.01456789]\n",
    "# [cart_position, cart_velocity, pole_angle, pole_angular_velocity]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cab052",
   "metadata": {},
   "source": [
    "# Physics Model: CartPole-v1 Dynamics\n",
    "\n",
    "To predict the next state of the environment, we implement the exact **Equations of Motion** used in the OpenAI Gym source code. This allows us to perform a \"Lookahead\" step to verify which action yields a better outcome.\n",
    "\n",
    "### 1. System Constants\n",
    "The environment uses fixed physical properties to simulate the dynamics:\n",
    "* **Gravity ($g$):** $9.8 \\, m/s^2$\n",
    "* **Mass of Cart ($M_c$):** $1.0 \\, kg$\n",
    "* **Mass of Pole ($M_p$):** $0.1 \\, kg$\n",
    "* **Total Mass ($M$):** $M_c + M_p = 1.1 \\, kg$\n",
    "* **Pole Half-Length ($L$):** $0.5 \\, m$ (Distance to center of mass)\n",
    "* **Force Magnitude ($F$):** $10.0 \\, N$\n",
    "* **Time Step ($\\tau$):** $0.02 \\, s$\n",
    "\n",
    "### 2. State Variables\n",
    "The system is defined by a 4-dimensional state vector:\n",
    "1.  $x$: Cart Position ($0$ = Center)\n",
    "2.  $\\dot{x}$: Cart Velocity\n",
    "3.  $\\theta$: Pole Angle ($0$ = Upright, Radians)\n",
    "4.  $\\dot{\\theta}$: Pole Angular Velocity\n",
    "\n",
    "### 3. Equations of Motion\n",
    "We derive the accelerations using Newtonian mechanics.\n",
    "\n",
    "**A. Intermediate Helper Term**\n",
    "First, we calculate a temporary term representing the effective force on the pole's center of mass (incorporating the applied force and centrifugal force):\n",
    "$$\\text{temp} = \\frac{F_{app} + M_p L \\dot{\\theta}^2 \\sin\\theta}{M}$$\n",
    "\n",
    "**B. Angular Acceleration ($\\ddot{\\theta}$)**\n",
    "This determines how the pole's rotation changes. It balances gravity against the cart's acceleration:\n",
    "$$\\ddot{\\theta} = \\frac{g \\sin\\theta - \\cos\\theta \\cdot \\text{temp}}{L \\left( \\frac{4}{3} - \\frac{M_p \\cos^2\\theta}{M} \\right)}$$\n",
    "\n",
    "**C. Linear Acceleration ($\\ddot{x}$)**\n",
    "This determines how the cart's velocity changes:\n",
    "$$\\ddot{x} = \\text{temp} - \\frac{M_p L \\ddot{\\theta} \\cos\\theta}{M}$$\n",
    "\n",
    "### 4. Euler Integration (Next State Update)\n",
    "The simulator assumes discrete time steps. We calculate the next state ($t+1$) by adding the change over time $\\tau$:\n",
    "\n",
    "* **New Position:** $x_{t+1} = x_t + \\tau \\cdot \\dot{x}_t$\n",
    "* **New Velocity:** $\\dot{x}_{t+1} = \\dot{x}_t + \\tau \\cdot \\ddot{x}_t$\n",
    "* **New Angle:** $\\theta_{t+1} = \\theta_t + \\tau \\cdot \\dot{\\theta}_t$\n",
    "* **New Angular Vel:** $\\dot{\\theta}_{t+1} = \\dot{\\theta}_t + \\tau \\cdot \\ddot{\\theta}_t$\n",
    "\n",
    "---\n",
    "*Note: The factor $\\frac{4}{3}$ in the angular acceleration equation accounts for the moment of inertia of a uniform rod rotating about one end.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c363ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# 1. Define the Physics Constants (from CartPole-v1 source)\n",
    "GRAVITY = 9.8\n",
    "MASSCART = 1.0\n",
    "MASSPOLE = 0.1\n",
    "TOTAL_MASS = (MASSCART + MASSPOLE)\n",
    "LENGTH = 0.5  # actually half the pole's length\n",
    "POLEMASS_LENGTH = (MASSPOLE * LENGTH)\n",
    "FORCE_MAG = 10.0\n",
    "TAU = 0.02  # seconds between updates\n",
    "\n",
    "def get_next_state(state, action):\n",
    "    \"\"\"\n",
    "    Simulates the physics equations for one time step.\n",
    "    Args:\n",
    "        state: [x, x_dot, theta, theta_dot]\n",
    "        action: 0 (Left) or 1 (Right)\n",
    "    Returns:\n",
    "        next_state: The predicted state after 0.02s\n",
    "    \"\"\"\n",
    "    x, x_dot, theta, theta_dot = state\n",
    "    \n",
    "    # Convert discrete action to force direction\n",
    "    force = FORCE_MAG if action == 1 else -FORCE_MAG\n",
    "    \n",
    "    # --- The Physics Equations (Equation of Motion) ---\n",
    "    costheta = math.cos(theta)\n",
    "    sintheta = math.sin(theta)\n",
    "\n",
    "    # Temporary variable for the linear force calculation\n",
    "    temp = (force + POLEMASS_LENGTH * theta_dot**2 * sintheta) / TOTAL_MASS\n",
    "    \n",
    "    # Calculate Angular Acceleration (theta_double_dot)\n",
    "    thetaacc = (GRAVITY * sintheta - costheta * temp) / (LENGTH * (4.0/3.0 - MASSPOLE * costheta**2 / TOTAL_MASS))\n",
    "    \n",
    "    # Calculate Linear Acceleration (x_double_dot)\n",
    "    xacc = temp - POLEMASS_LENGTH * thetaacc * costheta / TOTAL_MASS\n",
    "\n",
    "    # --- Euler Integration (Update State) ---\n",
    "    x_new = x + TAU * x_dot\n",
    "    x_dot_new = x_dot + TAU * xacc\n",
    "    theta_new = theta + TAU * theta_dot\n",
    "    theta_dot_new = theta_dot + TAU * thetaacc\n",
    "\n",
    "    return (x_new, x_dot_new, theta_new, theta_dot_new)\n",
    "\n",
    "def calculate_cost(state):\n",
    "    \"\"\"\n",
    "    Evaluates how 'bad' a state is. \n",
    "    Lower cost = Better state.\n",
    "    \"\"\"\n",
    "    x, x_dot, theta, theta_dot = state\n",
    "    \n",
    "    # We want the pole upright (theta=0) and the cart in the center (x=0).\n",
    "    # We give much higher weight to the angle because falling ends the game immediately.\n",
    "    \n",
    "    angle_penalty = abs(theta) * 10.0      # Heavy penalty for tipping\n",
    "    velocity_penalty = abs(theta_dot) * 1.0 # Penalty for swinging fast\n",
    "    position_penalty = abs(x) * 0.1        # Small penalty for drifting from center\n",
    "    \n",
    "    return angle_penalty + velocity_penalty + position_penalty\n",
    "\n",
    "def choose_best_action(current_state):\n",
    "    \"\"\"\n",
    "    Simulates both moves and picks the winner.\n",
    "    \"\"\"\n",
    "    # 1. Simulate the outcome of moving LEFT (Action 0)\n",
    "    next_state_left = get_next_state(current_state, 0)\n",
    "    cost_left = calculate_cost(next_state_left)\n",
    "    \n",
    "    # 2. Simulate the outcome of moving RIGHT (Action 1)\n",
    "    next_state_right = get_next_state(current_state, 1)\n",
    "    cost_right = calculate_cost(next_state_right)\n",
    "    \n",
    "    # 3. Compare and decide\n",
    "    if cost_left < cost_right:\n",
    "        return 0 # Go Left\n",
    "    else:\n",
    "        return 1 # Go Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2141bae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished with total reward: 318.0\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "# Create our training environment - a cart with a pole that needs balancing\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "# Reset environment to start a new episode\n",
    "# observation, info = env.reset()\n",
    "\n",
    "state, _ = env.reset()\n",
    "episode_over = False\n",
    "total_reward = 0\n",
    "\n",
    "while not episode_over:\n",
    "    # Use our physics model to pick the move\n",
    "    action = choose_best_action(state)\n",
    "    \n",
    "    # Step the real environment\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # reward: +1 for each step the pole stays upright\n",
    "    # terminated: True if pole falls too far (agent failed)\n",
    "    # truncated: True if we hit the time limit (500 steps)\n",
    "\n",
    "    total_reward += reward\n",
    "    episode_over = terminated or truncated\n",
    "\n",
    "print(f\"Episode finished with total reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bff963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished! Total reward: 51.0\n"
     ]
    }
   ],
   "source": [
    "episode_over = False\n",
    "total_reward = 0\n",
    "\n",
    "while not episode_over:\n",
    "    # Choose an action: 0 = push cart left, 1 = push cart right\n",
    "    action = env.action_space.sample()  # Random action for now - real agents will be smarter!\n",
    "\n",
    "    # Take the action and see what happens\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # reward: +1 for each step the pole stays upright\n",
    "    # terminated: True if pole falls too far (agent failed)\n",
    "    # truncated: True if we hit the time limit (500 steps)\n",
    "\n",
    "    total_reward += reward\n",
    "    episode_over = terminated or truncated\n",
    "\n",
    "print(f\"Episode finished! Total reward: {total_reward}\")\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iitj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
